{
    "model_name": "Qwen/Qwen-0.5B-Chat",
    "lora_rank": 8,
    "lora_alpha": 16,
    "target_modules": ["q_proj","v_proj"],
    "lr": 5e-5,
    "epoch": 10,
    "target_layers":[20,21,22,23]
}